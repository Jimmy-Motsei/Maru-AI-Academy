# Capstone Assignment — Your First Live Workflow

**Goal:** Ship a **live** workflow that saves time every day.

**Time:** 1-2 weeks (including 1 week live operation)

## Deliverables (upload as a single pack)

1. **Workflow Canvas** (Section 2 fields filled in)
2. **SOP (one page)** with screenshots
3. **Prompts/Templates** used (final versions)
4. **Evidence log** (10+ rows) with **minutes saved** per run
5. **Before/After** sample outputs (anonymized)
6. **3-line reflection:** what worked, what you'll improve next

## Pass criteria (Open Badge)

- Runs live for **one week** with human review in place
- Clear time savings demonstrated (e.g., ≥60 minutes total saved in the week)
- Safety rules followed (no personal data leaks; grounded outputs)

## Steps

### Step 1: Choose your capstone project (1 day)
Use the 3 filters from Section 1:
- **Frequent**: happens daily or weekly
- **Repeatable**: similar inputs each time
- **Safe**: uses green or anonymized data; has human review

**Examples:**
- Enquiry → reply draft → human approve → send → log
- Meeting notes → action items → weekly reminder
- Report text → decision summary → task table

### Step 2: Design your workflow (1 day)
Complete the Workflow Canvas with:
- **Name**: Clear, descriptive name
- **Trigger**: What starts the workflow
- **Steps**: 2-4 actions in order
- **Human review**: Where you approve/decline
- **Data rules**: Green/yellow/red; what to anonymize
- **Prompt(s)**: Your final templates
- **Outputs**: What gets created
- **Log fields**: What to track
- **Tools**: Which AI tools you'll use
- **Risks & mitigations**: What can go wrong + your checks

### Step 3: Build and test (2-3 days)
**Build tips:**
- Keep to 2-3 actions plus human approval
- Use your 5-part prompts with tone, word limits, and "no invented facts"
- Store prompts as templates for consistency

**Test plan (15-20 min):**
- Dry-run on 3-5 past examples (anonymized)
- Check tone, facts, and format
- Test edge cases: missing info, unclear requests, long messages
- Fix prompts or add checks where outputs failed

### Step 4: Measure impact (ongoing)
**Baseline today:**
- Time per task (minutes)
- Volume per day/week
- Error rate (if any)

**After launch:**
- Log minutes saved per run
- Track any corrections made
- Calculate total impact

**Weekly scorecard:**
- Volume handled
- Avg response time (before vs after)
- Minutes saved (sum)
- Quality notes (any fixes)
- Next improvement

### Step 5: Document and handover (1 day)
Create a one-page SOP with:
- **Purpose**: What this workflow delivers
- **When it runs**: Trigger and frequency
- **How to run**: Steps 1-4 (with screenshots)
- **Human review**: What to check before sending
- **Data rules**: What's allowed, what to anonymize
- **Troubleshooting**: Common issues and fixes
- **Owner & backup**: Who maintains it

Include your safety policy: "No invented facts. Ask when unsure. Cite sources where needed. Human review required."

### Step 6: Launch and support (1 week)
**Launch plan:**
- Start with one team or one inbox for a week
- Announce who's on approval duty and expected reply times
- Monitor the log daily; adjust prompts as needed
- Collect wins to share in your next meeting

**After week 1:**
- Widen to more users; keep approval step until error rate is near zero
- Set monthly cost cap and alerts

## AI Rubric (what's scored)

- **Function & safety (40%)** — trigger, steps, approval, data rules
- **Quality & clarity (30%)** — outputs are usable; SOP is easy to follow
- **Impact (30%)** — logged minutes saved align with workflow volume

## Success criteria

- Complete workflow canvas is filled out
- SOP is clear and includes screenshots
- Prompts are well-structured and safe
- Evidence log shows consistent time savings
- Before/after samples demonstrate improvement
- Reflection shows learning and future plans

## Pro tips

- Start simple and add complexity later
- Test thoroughly before going live
- Monitor closely during the first week
- Document everything as you go
- Celebrate wins and share success stories
- Use data to prove value and get buy-in

## Troubleshooting

- **If workflow is too complex**: Simplify to 2-3 actions
- **If outputs are poor**: Improve prompts and add examples
- **If human review is slow**: Streamline the review process
- **If logging is difficult**: Use simple tools like Google Sheets
- **If team resistance**: Share wins and success stories
- **If costs are high**: Switch to cheaper models or reduce frequency

## Congratulations!

You've successfully launched your first live AI workflow. This is a major milestone in your AI journey and demonstrates your ability to create practical, safe, and valuable automation.