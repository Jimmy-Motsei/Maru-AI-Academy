# 4.2 Instrumentation & data model (log once, learn forever)

## Instructor Script (3-5 min)

If you **don't log it**, you can't improve it. Standardize your log across workflows.

### Minimal Log Schema (per run)

**Required fields:**

- `timestamp` - When the run occurred
- `workflow_name` - Which automation was used
- `trigger` - What started the process
- `owner` - Who is responsible
- `input_size` - Size/complexity of input
- `outcome` - Success/failure/partial
- `approval_time_sec` - Time to human approval
- `model_tier` - Which AI model was used
- `tokens_or_cost` - Resource consumption
- `minutes_saved` - Time ROI calculation
- `notes` - Additional context

### Why Each Field Matters

**Owner** - for accountability and performance tracking
**Approval time** - identifies bottlenecks in human review
**Model tier/cost** - enables spend control and optimization
**Minutes saved** - proves ROI and business value
**Outcome** - tracks success rates and failure patterns

### Data Protection

- Keep **personal data out** or anonymize (POPIA compliance)
- Use consistent anonymization patterns
- Set appropriate retention periods (90-180 days)
- Implement access controls

### Storage Strategy

**Start simple:** Use a Sheet/DB with basic queries
**Scale up:** Move to data warehouse/BI tools
**Ensure:** Retention policies and access controls

## Example Log Entry

```
timestamp: 2024-09-22 14:30:00
workflow_name: lead_handling_v2
trigger: web_form_submission
owner: sales_team
input_size: medium
outcome: success
approval_time_sec: 180
model_tier: gpt-3.5-turbo
tokens_or_cost: $0.15
minutes_saved: 8
notes: high-quality lead, quick approval
```

## Key Takeaways

- Standardize logging across all workflows
- Include both operational and business metrics
- Protect personal data and comply with POPIA
- Start simple, scale as needed
