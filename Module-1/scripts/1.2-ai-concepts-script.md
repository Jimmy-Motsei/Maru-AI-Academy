# 1.2 — AI Concepts You’ll Actually Use (Instructor Script)

**Length:** ~8–10 min

## Plain‑language definitions
- **LLM**: a pattern‑predictor trained on text; it guesses the next token.
- **Token**: a chunk of text; pricing/limits depend on tokens, not characters.
- **Prompt**: your *spec* to the model; clear structure = better outputs.
- **System vs User** prompts: tone/role vs task/data.
- **Context window**: how much the model can "remember" at once.
- **Embeddings**: numeric fingerprints of text for search/matching.
- **Inference**: the act of generating outputs from the model.
- **Latency & cost**: each call has time + rand cost; optimize later via caching and smaller models.

## The 5‑step prompt loop
1) Clarify goal & constraints  
2) Provide structured inputs & examples  
3) Ask for a specific output format  
4) Test with edge cases  
5) Reflect + iterate (record learnings)

## Safety & ethics (lite)
- Data handling: avoid pasting secrets; mask PII in demos.
- Attribution: be honest where AI wrote/supports work.
