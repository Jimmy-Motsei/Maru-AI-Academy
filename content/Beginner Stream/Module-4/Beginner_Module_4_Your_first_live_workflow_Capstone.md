# Beginner Track — Module 4: Your first live workflow (Capstone)

Format per section:
- **Section heading**
- **Video-ready instructor script** (2–4 min, plain English)
- **Short quiz** (3 questions) with correct answers + brief rationales

---

## Section 1: Pick the right capstone (simple & valuable)

### Instructor Script
Welcome to your capstone! You’ll ship **one live workflow** that saves real time every day. Keep it **simple, safe, and visible**.

**How to choose (3 filters):**
1) **Frequent** — happens daily or weekly (emails, follow-ups, summaries).  
2) **Repeatable** — similar inputs each time (enquiries, status updates).  
3) **Safe** — uses **green** or anonymized data; has a built-in **human review** step.

**Good examples:**
- Enquiry → reply draft → human approve → send → log.  
- Meeting notes → action items → weekly reminder.  
- Report text → decision summary → task table.

**Avoid for capstone v1:** legal contracts, payroll, anything needing sensitive personal data.

### Quiz (3 questions)
1) A strong capstone is **not** usually:  
   **B. A rare, once-a-year task.**  
   *Rationale:* Choose frequent work to get real savings.

2) Which is safest for a first live workflow?  
   **C. A process using green or anonymized data with human review.**  
   *Rationale:* Safety + oversight.

3) A good sign of repeatability is:  
   **B. Similar inputs each time.**  
   *Rationale:* Templates work best on repeatable tasks.

---

## Section 2: Design the workflow (map steps, roles, guardrails)

### Instructor Script
Design before you build. Use this one-page canvas:

**Workflow Canvas (copy this):**
- **Name:** e.g., “Enquiry Auto-Reply + Log”  
- **Trigger:** what starts it (form/email/meeting end)  
- **Steps:** list 2–4 actions in order  
- **Human review:** where you approve/decline  
- **Data rules:** green/yellow/red; what to anonymize  
- **Prompt(s):** paste your final templates  
- **Outputs:** email/summary/task table/notes  
- **Log fields:** timestamp, owner, outcome, minutes saved  
- **Tools:** chat assistant, doc helper, sheet; who owns them  
- **Risks & mitigations:** what can go wrong + your check

**Pro tip:** Make the **human review** step explicit: *“If missing contact or unclear request → ask for info; do not send.”*

### Quiz (3 questions)
1) The **Trigger** describes:  
   **C. The event that starts the workflow.**  
   *Rationale:* It kicks things off.

2) Guardrails should include:  
   **B. Data rules and when to stop or ask for info.**  
   *Rationale:* Prevents unsafe sends.

3) Logging “minutes saved” helps you:  
   **B. Measure ROI and prove impact.**  
   *Rationale:* Links to business value.

---

## Section 3: Build & test (dry runs, edge cases, tone)

### Instructor Script
Now build a **small first version** and test it.

**Build tips:**
- Keep to **2–3 actions** plus **human approval**.  
- Use your **5-part prompts** with tone, word limits, and “no invented facts.”  
- Store prompts as templates so every run is consistent.

**Test plan (15–20 min):**
- **Dry-run** on 3–5 past examples (anonymized).  
- Check **tone** (polite, clear, local context), **facts**, and **format**.  
- **Edge cases:** missing phone/email, unclear request, long messages.  
- Fix prompts or add checks where outputs failed.

**Only then** switch the flow to live.

### Quiz (3 questions)
1) Before going live you should:  
   **B. Dry-run with 3–5 examples and fix issues.**  
   *Rationale:* Catch problems early.

2) To reduce hallucinations you add:  
   **B. “No invented facts; ask when unsure.”**  
   *Rationale:* Guardrail in Rules.

3) One reason to set word limits is to:  
   **B. Keep outputs short and easy to read.**  
   *Rationale:* Fits business comms.

---

## Section 4: Measure impact (baseline, scorecard, weekly review)

### Instructor Script
Proving value keeps momentum.

**Baseline today:** time per task (minutes), volume per day/week, error rate (if any).  
**After launch:** log **minutes saved** per run and any corrections you made.

**AI scorecard (weekly):**
- Volume handled  
- Avg response time (before vs after)  
- Minutes saved (sum)  
- Quality notes (any fixes)  
- Next improvement

**Goal for beginners:** achieve **consistent savings** (e.g., 8–15 minutes per run), not perfection.

### Quiz (3 questions)
1) Baseline numbers help you:  
   **B. Compare before vs after to show gains.**  
   *Rationale:* Evidence of impact.

2) A simple scorecard includes:  
   **B. Volume, response time, minutes saved, quality notes.**  
   *Rationale:* Core metrics.

3) Early on, aim for:  
   **C. Consistent time savings, then refine quality.**  
   *Rationale:* Value first, polish next.

---

## Section 5: Document & handover (SOP + policy in one page)

### Instructor Script
Document so others can use it.

**SOP (one page):**
- **Purpose:** what this workflow delivers  
- **When it runs:** trigger and frequency  
- **How to run:** steps 1–4 (with screenshots)  
- **Human review:** what to check before sending  
- **Data rules:** what’s allowed, what to anonymize  
- **Troubleshooting:** common issues and fixes  
- **Owner & backup:** who maintains it

**Policy reminder:** copy your safety line into the SOP: *“No invented facts. Ask when unsure. Cite sources where needed. Human review required.”*

### Quiz (3 questions)
1) The SOP should mainly explain:  
   **B. Purpose, when it runs, how to run, and checks.**  
   *Rationale:* Actionable steps.

2) Including screenshots helps because:  
   **B. New users can follow the process easily.**  
   *Rationale:* Visual guidance.

3) A policy line to include is:  
   **B. No invented facts; ask when unsure; human review required.**  
   *Rationale:* Safety by default.

---

## Section 6: Launch & support (go live, monitor, iterate)

### Instructor Script
It’s launch time—keep it calm and reversible.

**Launch plan:**
- Start with **one team** or **one inbox** for a week.  
- Announce who’s on **approval duty** and expected reply times.  
- Monitor the log daily; adjust prompts as needed.  
- Collect **wins** (minutes saved, happy replies) to share in your next meeting.

**After week 1:** widen to more users; keep the approval step until error rate is near zero. Set a **monthly cost cap** and alerts.

### Quiz (3 questions)
1) A low-risk launch starts with:  
   **B. One team or inbox for a week.**  
   *Rationale:* Controlled rollout.

2) During the first week, you should:  
   **B. Monitor logs daily and tweak prompts.**  
   *Rationale:* Fast feedback loop.

3) Approval steps should be removed when:  
   **C. Error rate is near zero and team is confident.**  
   *Rationale:* Only when stable.

---

## Capstone Assignment (Beginner, Module 4)

**Goal:** Ship a **live** workflow that saves time every day.

**Deliverables (upload as a single pack):**
1) **Workflow Canvas** (Section 2 fields filled in).  
2) **SOP (one page)** with screenshots.  
3) **Prompts/Templates** used (final versions).  
4) **Evidence log** (10+ rows) with **minutes saved** per run.  
5) **Before/After** sample outputs (anonymized).  
6) **3-line reflection:** what worked, what you’ll improve next.

**Pass criteria (Open Badge):**
- Runs live for **one week** with human review in place.  
- Clear time savings demonstrated (e.g., ≥60 minutes total saved in the week).  
- Safety rules followed (no personal data leaks; grounded outputs).

**AI Rubric (what’s scored):**
- **Function & safety (40%)** — trigger, steps, approval, data rules.  
- **Quality & clarity (30%)** — outputs are usable; SOP is easy to follow.  
- **Impact (30%)** — logged minutes saved align with the workflow volume.

---

### End of Module 4 — Congratulations!
You’ve launched your first live AI workflow, documented it, measured the value, and earned your **AI Foundations (Beginner)** badge. Next step: consider the **Intermediate track** to scale this into multi-step, team-wide automations.
